{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### embed data string to list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "## load_data\n",
    "with open(\"../data/all.review.vec.txt\", 'r', encoding=\"UTF8\") as f:\n",
    "    review_vec = f.readlines()\n",
    "all_review_vec = review_vec[1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "embed_vec = np.zeros((56050, 100))\n",
    "key_word = []\n",
    "for i in range(len(all_review_vec)):\n",
    "    key_word.append(all_review_vec[i].split()[0])\n",
    "    for j in range(100):\n",
    "        embed_vec[i, j] = float(all_review_vec[i].split()[j+1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "56050"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_vec_dict = {}\n",
    "for i in range(len(key_word)):\n",
    "    embed_vec_dict[key_word[i]] = embed_vec[i, :]\n",
    "len(embed_vec_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### split token"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "positive_files = glob.glob(\"../data/train/positive/*\")\n",
    "negative_files = glob.glob(\"../data/train/negative/*\")\n",
    "total_files = positive_files + negative_files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_num :  9 , max_num :  3817 , token_list : 375720\n"
     ]
    }
   ],
   "source": [
    "token_list = []\n",
    "token_counts = []\n",
    "for file_root in total_files:\n",
    "    file = open(file_root, 'r', encoding=\"UTF8\")\n",
    "    reviews = file.readline()\n",
    "    token = word_tokenize(reviews)\n",
    "    token_list += token\n",
    "    token_counts.append(len(token))\n",
    "print('min_num : ', np.min(token_counts) ,',', 'max_num : ', np.max(token_counts),',', 'token_list :', len(token_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### delete token which is not in review_vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_list : 369990\n"
     ]
    }
   ],
   "source": [
    "for i in reversed(range(len(token_list))):\n",
    "    if token_list[i] not in key_word:\n",
    "        del token_list[i]\n",
    "print('token_list :', len(token_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### most word token within 10k"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_token : 19388\n"
     ]
    }
   ],
   "source": [
    "count = Counter(token_list)\n",
    "print('unique_token :', len(count))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_token : 10000\n"
     ]
    }
   ],
   "source": [
    "most_count = count.most_common(10000)\n",
    "print('unique_token :', len(most_count))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "most_token = []\n",
    "\n",
    "for token, count in most_count:\n",
    "    most_token.append(token)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### most 10k token embedding preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wonsang\\anaconda3\\envs\\ca1\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  token                                   embedding_vector\n0   the  [0.077042, -0.138293, 0.045446, 0.001055, -0.0...\n1     ,  [0.077455, -0.196322, -0.036069, -0.026043, -0...\n2     .  [0.10809, -0.2071, -0.018723, -2.7e-05, -0.143...\n3   and  [0.096765, -0.117544, 0.010411, 0.008122, -0.1...\n4    of  [0.188291, -0.204709, 0.006558, -0.132994, -0....",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>embedding_vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the</td>\n      <td>[0.077042, -0.138293, 0.045446, 0.001055, -0.0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>,</td>\n      <td>[0.077455, -0.196322, -0.036069, -0.026043, -0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>.</td>\n      <td>[0.10809, -0.2071, -0.018723, -2.7e-05, -0.143...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>and</td>\n      <td>[0.096765, -0.117544, 0.010411, 0.008122, -0.1...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>of</td>\n      <td>[0.188291, -0.204709, 0.006558, -0.132994, -0....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embed = pd.DataFrame({\"token\": [], \"embedding_vector\": []})\n",
    "\n",
    "for i in range(len(most_count)):\n",
    "    final_embed.loc[i] = [most_token[i], embed_vec_dict[most_token[i]].tolist()]\n",
    "final_embed.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "with open('../data/10k_embed.txt', 'w') as f:\n",
    "    for i, vector in enumerate(final_embed[\"embedding_vector\"]):\n",
    "        tmp = [str(embed) for embed in vector]\n",
    "        output = str(i) + ' '+ ' '.join(tmp) + '\\n'\n",
    "        f.write(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative_list:  1000  positive_list : 1000\n"
     ]
    }
   ],
   "source": [
    "train_negative_list = glob.glob(\"../data/train/negative/*\")\n",
    "train_positive_list = glob.glob(\"../data/train/positive/*\")\n",
    "print( 'negative_list: ', len(train_negative_list),' ' +  'positive_list :', len(train_positive_list))\n",
    "train_total_list = train_negative_list + train_positive_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "tags_word2idx = {}\n",
    "for i in range(len(most_token)):\n",
    "    tags_word2idx[most_token[i]] = i"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = np.zeros((2000, 3774)) # 3817\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/train/negative\\1909\n",
      "../data/train/negative\\1916\n",
      "../data/train/negative\\1917\n",
      "../data/train/negative\\1918\n",
      "../data/train/negative\\192\n",
      "../data/train/negative\\1920\n",
      "../data/train/negative\\1922\n",
      "../data/train/negative\\1924\n",
      "../data/train/negative\\1926\n",
      "../data/train/negative\\1927\n",
      "../data/train/negative\\1928\n",
      "../data/train/negative\\1929\n"
     ]
    }
   ],
   "source": [
    "for i, file_root in enumerate(train_total_list):\n",
    "    file = open(file_root, 'r', encoding=\"UTF8\")\n",
    "    reviews = file.readline()\n",
    "    if file_root in train_negative_list:\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    token = word_tokenize(reviews)\n",
    "    for k in reversed(range(len(token))):\n",
    "        if (token[k] not in key_word):\n",
    "            del token[k]\n",
    "\n",
    "    for j in range(len(token)):\n",
    "        if token[j] in most_token:\n",
    "            train[i, j] = tags_word2idx[token[j]]\n",
    "        else:\n",
    "            train[i, j] = 0\n",
    "        train[i, 3773] = label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "np.save(\"../data/train_data\", train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative_list:  0  positive_list : 0\n"
     ]
    }
   ],
   "source": [
    "test_list = glob.glob(\"../data/test/*\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "test = np.zeros((2000, 3774)) # 3817"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "for i, file_root in enumerate(test_list):\n",
    "    file = open(file_root, 'r', encoding=\"UTF8\")\n",
    "    reviews = file.readline()\n",
    "    token = word_tokenize(reviews)\n",
    "    for k in reversed(range(len(token))):\n",
    "        if (token[k] not in key_word):\n",
    "            del token[k]\n",
    "\n",
    "    for j in range(len(token)):\n",
    "        if token[j] in most_token:\n",
    "            test[i, j] = tags_word2idx[token[j]]\n",
    "        else:\n",
    "            test[i, j] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "np.save(\"../data/test_data\", test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}